# ETL de CSV para JSON

![Python](https://img.shields.io/badge/Python-3.11%2B-blue?style=for-the-badge&logo=python)
![Tests](https://img.shields.io/badge/Tests-Pytest-green?style=for-the-badge&logo=pytest)
![Coverage](https://img.shields.io/badge/Coverage-85%25-brightgreen?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-purple?style=for-the-badge)

> Pipeline de ETL (Extract, Transform, Load) construÃ­do em Python. Este projeto processa arquivos CSV de perfis de clientes, aplica validaÃ§Ãµes rigorosas de schema e transforma os dados, salvando o resultado em formato JSON. Idealizado como uma peÃ§a de portfÃ³lio para demonstrar boas prÃ¡ticas de desenvolvimento, incluindo testes automatizados e cÃ³digo modular.

<br>

##  navegar
* [ğŸ“Œ Sobre o Projeto](#-sobre-o-projeto)
* [âœ¨ Funcionalidades](#-funcionalidades)
* [ğŸ’» Tecnologias Utilizadas](#-tecnologias-utilizadas)
* [ğŸš€ Como Executar o Projeto](#-como-executar-o-projeto)
* [ğŸ§ª Como Rodar os Testes](#-como-rodar-os-testes)
* [ğŸ“ Estrutura de Pastas](#-estrutura-de-pastas)
* [ğŸ§  PrÃ³ximos Passos](#-prÃ³ximos-passos)
* [ğŸ‘¨â€ğŸ’» Autor](#-autor)

---

## ğŸ“Œ Sobre o Projeto

O objetivo deste ETL Ã© garantir a integridade e a qualidade dos dados que entram em um sistema. O pipeline extrai dados de um arquivo `CRM_profiles.csv`, valida se cada registro atende a um schema prÃ©-definido (campos obrigatÃ³rios, tipos de dados), realiza transformaÃ§Ãµes como limpeza de espaÃ§os e padronizaÃ§Ã£o, e carrega os dados validados em um arquivo `CRM_profiles.json`. Erros de validaÃ§Ã£o sÃ£o registrados em logs para fÃ¡cil rastreabilidade.

---

## âœ¨ Funcionalidades

-   **ExtraÃ§Ã£o (Extract):** Leitura de dados a partir de arquivos `.csv`.
-   **ValidaÃ§Ã£o de Schema:** Garante que os dados de entrada possuam a estrutura correta (campos, tipos, etc.).
-   **TransformaÃ§Ã£o (Transform):** Limpeza de dados, como remoÃ§Ã£o de espaÃ§os em branco e tratamento de valores nulos.
-   **Carga (Load):** Salvamento dos dados processados e vÃ¡lidos em formato `.json`.
-   **Logging Detalhado:** Registra cada etapa do processo, incluindo erros de validaÃ§Ã£o e sucesso na execuÃ§Ã£o.
-   **Testes UnitÃ¡rios:** Cobertura de testes robusta para as funÃ§Ãµes de extraÃ§Ã£o, transformaÃ§Ã£o e carga, garantindo a confiabilidade do pipeline.

---

## ğŸ’» Tecnologias Utilizadas

Este projeto foi construÃ­do com as seguintes tecnologias:

-   **Python 3.11+**
-   **Pytest** (para testes unitÃ¡rios)
-   **pytest-cov** (para relatÃ³rio de cobertura de testes)
-   MÃ³dulo `typing` para tipagem estÃ¡tica
-   MÃ³dulo `logging` para logs estruturados
-   MÃ³dulo `csv` e `json` para manipulaÃ§Ã£o de arquivos

---

## ğŸš€ Como Executar o Projeto

Siga os passos abaixo para executar o projeto localmente.

### **PrÃ©-requisitos**

-   [Python 3.11](https://www.python.org/downloads/) ou superior
-   [Git](https://git-scm.com/downloads)

### **Passo a Passo**

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/seu-usuario/ETL_CSV_TO_JSON.git](https://github.com/seu-usuario/ETL_CSV_TO_JSON.git)
    cd ETL_CSV_TO_JSON
    ```

2.  **Crie e ative um ambiente virtual:**
    ```bash
    # Linux / macOS
    python3 -m venv venv
    source venv/bin/activate

    # Windows
    python -m venv venv
    .\venv\Scripts\activate
    ```

3.  **Instale as dependÃªncias:**
    *(ObservaÃ§Ã£o: Crie um arquivo `requirements.txt` com as bibliotecas `pytest` e `pytest-cov`)*
    ```bash
    pip install -r requirements.txt
    ```

4.  **Execute o Pipeline ETL:**
    O script principal irÃ¡ ler o arquivo de `data/input/CRM_profiles.csv` e gerar a saÃ­da em `data/output/CRM_profiles.json`.
    ```bash
    python etl/main.py
    ```

---

## ğŸ§ª Como Rodar os Testes

Os testes unitÃ¡rios foram criados para validar cada componente do pipeline.

Para executar os testes e ver o relatÃ³rio de cobertura no terminal, rode o comando na raiz do projeto:

```bash
pytest --cov=etl --cov-report term-missing
```

---

## ğŸ“ Estrutura de Pastas

O projeto estÃ¡ organizado da seguinte forma para garantir clareza e manutenibilidade:

```
ETL_CSV_TO_JSON/
â”‚
â”œâ”€â”€ .pytest_cache/      # Cache gerado pelo Pytest
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ CRM_profiles.csv  # Arquivo de dados brutos de entrada
â”‚   â””â”€â”€ output/
â”‚       â””â”€â”€ CRM_profiles.json # Arquivo de saÃ­da com dados processados
â”‚
â”œâ”€â”€ etl/                # MÃ³dulo principal da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py         # Ponto de entrada (entrypoint) para executar o pipeline
â”‚   â”œâ”€â”€ pipeline.py     # ContÃ©m a classe e a lÃ³gica do ETL
â”‚   â””â”€â”€ utils.py        # FunÃ§Ãµes auxiliares (ex: validaÃ§Ãµes)
â”‚
â”œâ”€â”€ tests/              # SuÃ­te de testes automatizados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_etl.py     # Testes unitÃ¡rios para o pipeline
â”‚
â”œâ”€â”€ .gitignore          # Arquivos e pastas a serem ignorados pelo Git
â””â”€â”€ readme.md           # DocumentaÃ§Ã£o do projeto
```

---

## ğŸ§  PrÃ³ximos Passos

-   [ ] IntegraÃ§Ã£o com um banco de dados (ex: PostgreSQL, MongoDB) como destino (Load).
-   [ ] Upload automÃ¡tico do arquivo JSON gerado para um serviÃ§o de nuvem (ex: AWS S3).
-   [ ] CriaÃ§Ã£o de uma Interface de Linha de Comando (CLI) para passar argumentos (ex: caminho do arquivo de entrada/saÃ­da).
-   [ ] OrquestraÃ§Ã£o do pipeline com ferramentas como Airflow ou Prefect.

---

## ğŸ‘¨â€ğŸ’» Autor

**Felipe GalvÃ£o**

-   LinkedIn: [`linkedin.com/in/felipe-galvao`](https://linkedin.com/in/felipe-galvÃ£o)
-   GitHub: [`github.com/felipegalvao`](https://github.com/felipegalvao)